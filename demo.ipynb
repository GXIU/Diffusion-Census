{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59785a45-0232-44f3-a70e-9ae76bb28ac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T14:43:39.793512Z",
     "iopub.status.busy": "2023-05-21T14:43:39.793246Z",
     "iopub.status.idle": "2023-05-21T14:43:41.917249Z",
     "shell.execute_reply": "2023-05-21T14:43:41.916597Z",
     "shell.execute_reply.started": "2023-05-21T14:43:39.793489Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ss\n",
    "import scipy.sparse.linalg as ssl\n",
    "import torch\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits import mplot3d\n",
    "from torch import nn\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df90bac-5746-4152-8e11-f63641fe8e54",
   "metadata": {},
   "source": [
    "# Correlation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e6bf83-36cf-4d49-b349-5d5cfc5b4716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T14:43:41.925426Z",
     "iopub.status.busy": "2023-05-21T14:43:41.925195Z",
     "iopub.status.idle": "2023-05-21T14:43:41.935476Z",
     "shell.execute_reply": "2023-05-21T14:43:41.935000Z",
     "shell.execute_reply.started": "2023-05-21T14:43:41.925405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pearsonr(data_from, data_to, row_based=True):\n",
    "    if not row_based:\n",
    "        x = torch.Tensor(data_from.values).T\n",
    "    else:\n",
    "        x = torch.Tensor(data_from.values)\n",
    "    y = torch.Tensor(data_to.values).repeat(x.shape[0], 1)\n",
    "    assert x.shape == y.shape\n",
    "    centered_x = x - x.mean(dim=1, keepdim=True)\n",
    "    centered_y = y - y.mean(dim=1, keepdim=True)\n",
    "    covariance = (centered_x * centered_y).sum(dim=1, keepdim=True)\n",
    "    bessel_corrected_covariance = covariance / (x.shape[1] - 1)\n",
    "    x_std = x.std(dim=dim, keepdim=True)\n",
    "    y_std = y.std(dim=dim, keepdim=True)\n",
    "    corr = (bessel_corrected_covariance / (x_std * y_std)).T[0].numpy()\n",
    "    if row_based:\n",
    "        return pd.Series(corr, data_from.index)\n",
    "    else:\n",
    "        return pd.Series(corr, data_from.columns)\n",
    "\n",
    "\n",
    "def pearsonr_against(data_from, data_super_to, batch_size=100, k=10, batch_first=True, row_based=True):\n",
    "    if row_based:\n",
    "        data_from, data_super_to = data_from.T, data_super_to.T\n",
    "    '''\n",
    "    Pearson_corr between a m x n dataframe and a m x k dataframe, returns an n * k correlation matrix.\n",
    "    Usage: A.corragainst(B)\n",
    "    '''\n",
    "    num_batches = int(np.ceil(data_super_to.shape[1] / batch_size))\n",
    "    corr_total = None\n",
    "\n",
    "    for i in trange(num_batches):\n",
    "        start_index = i * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "        batch_super_to = data_super_to.iloc[:, start_index:end_index]\n",
    "\n",
    "        x = torch.Tensor(data_from.values).repeat_interleave(\n",
    "            batch_super_to.shape[1], dim=1).T\n",
    "        y = torch.Tensor(batch_super_to.values).repeat(1, data_from.shape[1]).T\n",
    "        assert x.shape == y.shape\n",
    "\n",
    "        if batch_first:\n",
    "            dim = -1\n",
    "        else:\n",
    "            dim = 0\n",
    "\n",
    "        centered_x = x - x.mean(dim=dim, keepdim=True)\n",
    "        centered_y = y - y.mean(dim=dim, keepdim=True)\n",
    "        covariance = (centered_x * centered_y).sum(dim=dim, keepdim=True)\n",
    "        bessel_corrected_covariance = covariance / (x.shape[dim] - 1)\n",
    "        x_std = x.std(dim=dim, keepdim=True)\n",
    "        y_std = y.std(dim=dim, keepdim=True)\n",
    "        corr_batch = (bessel_corrected_covariance / (x_std * y_std)).T[0].numpy()\n",
    "\n",
    "        # Reshape and retain k largest correlations in each row and set the rest to 0\n",
    "        corr_batch_reshaped = corr_batch.reshape((data_from.shape[1], -1))\n",
    "        indices_of_k_largest = np.argpartition(corr_batch_reshaped, -k, axis=1)[:, -k-1:-1]\n",
    "        mask = np.ones(corr_batch_reshaped.shape, dtype=bool)\n",
    "        np.put_along_axis(mask, indices_of_k_largest, False, axis=1)\n",
    "        corr_batch_reshaped[mask] = 0\n",
    "        corr_batch = corr_batch_reshaped.flatten()\n",
    "\n",
    "        if corr_total is None:\n",
    "            corr_total = corr_batch\n",
    "        else:\n",
    "            corr_total = np.hstack((corr_total, corr_batch))\n",
    "            \n",
    "    return pd.Series(corr_total, pd.MultiIndex.from_product([data_from.columns, data_super_to.columns],\n",
    "                                                            names=[data_from.index.name, data_super_to.index.name]))\n",
    "\n",
    "pd.core.frame.DataFrame.corrwith = pearsonr\n",
    "pd.core.frame.DataFrame.corragainst = pearsonr_against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e306220-7a8d-4b03-9b67-2c6c858e833b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T14:43:42.689722Z",
     "iopub.status.busy": "2023-05-21T14:43:42.689394Z",
     "iopub.status.idle": "2023-05-21T14:43:42.973493Z",
     "shell.execute_reply": "2023-05-21T14:43:42.972901Z",
     "shell.execute_reply.started": "2023-05-21T14:43:42.689699Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "census_dir = 'census.csv'\n",
    "original_census = pd.read_csv(census_dir, index_col='GeographyCode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4985b0-78d5-4026-986f-522f66b63b28",
   "metadata": {},
   "source": [
    "# Standardizing Census Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fab1089-b13b-4775-a60c-3ddb944dd718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T15:06:07.021893Z",
     "iopub.status.busy": "2023-05-21T15:06:07.021625Z",
     "iopub.status.idle": "2023-05-21T15:06:07.027292Z",
     "shell.execute_reply": "2023-05-21T15:06:07.026764Z",
     "shell.execute_reply.started": "2023-05-21T15:06:07.021872Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. standardizing\n",
    "def standardized(original_census: pd.DataFrame,\n",
    "                how='z',\n",
    "                low=0.1,\n",
    "                high=99.9,\n",
    "                non_allowance=10000,\n",
    "                to_dir=\"./\"\n",
    "               ):\n",
    "    \"\"\"\n",
    "    Standardize the census data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    low : float, optional\n",
    "        The lower percentile to clip.\n",
    "    high : float, optional\n",
    "        The upper percentile to clip.\n",
    "    non_allowance : int, optional\n",
    "        The maximum number of missing values allowed.\n",
    "    census_dir : str, optional\n",
    "        The path to the original census data.\n",
    "    to_dir : str, optional\n",
    "        The path to the directory where the standardized data will be saved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The standardized census data.\n",
    "    \"\"\"\n",
    "    nan_check = original_census.isna()\n",
    "    census = pd.DataFrame(\n",
    "        original_census,\n",
    "        columns=nan_check.columns[nan_check.sum() < non_allowance].values,\n",
    "    )\n",
    "    census = census[census.isna().sum(axis=1) == 0]\n",
    "    \n",
    "    if how == 'z':\n",
    "        percentiles = np.percentile(census, [low, high], axis=0)\n",
    "        census = pd.DataFrame(census.clip(percentiles[0], percentiles[1]))\n",
    "        census = census - census.mean()\n",
    "        census = census / census.std(axis=0)\n",
    "        census = census.fillna(0)\n",
    "    elif how == 'rank':\n",
    "        census = 2 * census.rank() / census.shape[0] -1\n",
    "        census = census.fillna(0)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    census.sort_index(inplace=True)\n",
    "    census.to_hdf(f\"{to_dir}/standardized_census_{how}.hdf\", \"standardized_census\")\n",
    "    return census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a2ef91-681f-4d57-bfb1-68fb59f9e01d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T14:43:57.562942Z",
     "iopub.status.busy": "2023-05-21T14:43:57.562592Z",
     "iopub.status.idle": "2023-05-21T14:43:58.187758Z",
     "shell.execute_reply": "2023-05-21T14:43:58.187204Z",
     "shell.execute_reply.started": "2023-05-21T14:43:57.562918Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 589 ms, sys: 93.3 ms, total: 682 ms\n",
      "Wall time: 621 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "census = standardized(original_census, how='rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf45826-4a9e-41d9-9015-97f026c83b66",
   "metadata": {},
   "source": [
    "# Calculating pairwise distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9b36f-a438-4148-a1e0-e638cb086f50",
   "metadata": {},
   "source": [
    "## Distributed Distance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f7e358-c45e-433b-9714-a428df673287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T15:06:07.028472Z",
     "iopub.status.busy": "2023-05-21T15:06:07.028010Z",
     "iopub.status.idle": "2023-05-21T15:06:07.033454Z",
     "shell.execute_reply": "2023-05-21T15:06:07.032952Z",
     "shell.execute_reply.started": "2023-05-21T15:06:07.028448Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_distances(census, part_id, num_part=40, n_neighbors=100, to_dir=\"../data/pairwise_distances/\"):\n",
    "    data_to = torch.Tensor(census.values)\n",
    "    len_slice = int(data_to.shape[0] // (num_part - 1))\n",
    "    slice_ = census.iloc[part_id * len_slice: (part_id + 1) * len_slice, :]\n",
    "\n",
    "    distances = []\n",
    "    for location_id, feature in tqdm(slice_.iterrows()):\n",
    "        data_from = torch.Tensor(feature)  # m identical rows\n",
    "        data_from = data_from.repeat((data_to.shape[0], 1))\n",
    "        distance_vec = nn.functional.pairwise_distance(data_from, data_to, p=2).numpy()\n",
    "\n",
    "        # Keep only n_neighbors smallest distances, set the rest to a large value\n",
    "        indices_of_smallest = np.argpartition(distance_vec, n_neighbors)[:n_neighbors]\n",
    "        mask = np.ones(distance_vec.shape, dtype=bool)\n",
    "        mask[indices_of_smallest] = False\n",
    "        distance_vec[mask] = np.inf\n",
    "\n",
    "        result = pd.Series(distance_vec, index=census.index)\n",
    "        result = result.reset_index()\n",
    "        result.insert(0, \"ego\", location_id, True)\n",
    "        distances.append(result.values)\n",
    "\n",
    "    pd.to_pickle(distances, f\"{to_dir}/{part_id}.p\", protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6fd37-845d-4f19-9360-c3ba18ea13e5",
   "metadata": {},
   "source": [
    "## Correlation against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f840efcc-6eb8-476b-b683-3ae7b2d7c1f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T14:58:23.810132Z",
     "iopub.status.busy": "2023-05-21T14:58:23.809769Z",
     "iopub.status.idle": "2023-05-21T15:06:07.020568Z",
     "shell.execute_reply": "2023-05-21T15:06:07.019977Z",
     "shell.execute_reply.started": "2023-05-21T14:58:23.810109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [07:36<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 47s, sys: 3min 14s, total: 33min 2s\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# alternatively, we can just use corragainst. This can run in parallel\n",
    "corrs = census.iloc[:100000].corragainst(census.iloc[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5917b-50cb-4245-9ddb-d4f9f0ae0d9a",
   "metadata": {},
   "source": [
    "# Eigen decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e371f3e-7a52-41cb-b76e-d1f65dc77b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T15:06:11.667829Z",
     "iopub.status.busy": "2023-05-21T15:06:11.667488Z",
     "iopub.status.idle": "2023-05-21T15:06:11.675615Z",
     "shell.execute_reply": "2023-05-21T15:06:11.675111Z",
     "shell.execute_reply.started": "2023-05-21T15:06:11.667804Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eigen_decomposition(\n",
    "    census, pairwise_distance_dir, to_dir, shape_dir, # shapefile .shp\n",
    "    k=10, number_of_EVs=50, dist=True\n",
    "):\n",
    "    data_to = torch.Tensor(census.values)\n",
    "    shape = gpd.read_file(shape_dir).set_index(\"geo_code\")\n",
    "    pairwisefiles = [\n",
    "        x for x in os.listdir(pairwise_distance_dir) if (\".p\" in x) and (x[0] != \".\")\n",
    "    ]\n",
    "    pairwise_distances = np.concatenate(\n",
    "        [pd.read_pickle(f\"{pairwise_distance_dir}/\" + file)\n",
    "         for file in pairwisefiles]\n",
    "    )\n",
    "    edgelist = np.concatenate([x[:k]\n",
    "                              for x in tqdm(pairwise_distances)])  # k closest\n",
    "\n",
    "    # constructing complex network\n",
    "    indexing = dict(zip(census.index, np.arange(census.shape[0])))\n",
    "    sources = [indexing[x] for x in edgelist[:, 0]]\n",
    "    targets = [indexing[x] for x in edgelist[:, 1]]\n",
    "    From = sources + targets\n",
    "    To = targets + sources\n",
    "    if dist==True:\n",
    "        Prob = np.tile(1 / (edgelist[:, 2].astype(float)), 2)\n",
    "    else: # correlations\n",
    "        Prob = np.tile((edgelist[:, 2].astype(float)), 2)\n",
    "    X = ss.csr_matrix((Prob, (From, To)))  # sparse csr matrix\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(np.array([sources, targets]).T)\n",
    "    print(\n",
    "        f\"G of {X.shape[0]} nodes is connected for k = {k}? \", nx.is_connected(G))\n",
    "    for i, row in tqdm(enumerate(X)):\n",
    "        X[i, :] = row / np.sum(row)\n",
    "    adjacency = ss.identity(len(census.index), format=\"csr\") - X.tocsr()\n",
    "    print(\"adjacency matrix got\")\n",
    "    eigvals, eigvecs = ssl.eigs(adjacency, k=number_of_EVs, which=\"SR\")\n",
    "    sorts = np.argsort(eigvals.real)\n",
    "    eigvals, eigvecs = eigvals[sorts], eigvecs[:, sorts]\n",
    "    features = pd.DataFrame(eigvecs.real, index=census.index)\n",
    "    features.index.rename(\"geo_code\", inplace=True)\n",
    "\n",
    "    features = shape.join(features)\n",
    "\n",
    "    features.columns = features.columns.astype(str)\n",
    "    features.to_file(to_dir)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3b373-1f44-4afe-92bd-884ab5675765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T15:08:05.325292Z",
     "iopub.status.busy": "2023-05-21T15:08:05.324917Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrs.index.names = ['source', 'target']\n",
    "corrs.name = 'weight'\n",
    "G = nx.from_pandas_edgelist(corrs.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682b5c6-880e-4b73-a3be-92fc59d95109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. plotting\n",
    "\n",
    "\n",
    "def plotting(features_dir, to_dir, local_shape_dir=None, low=1, high=95):\n",
    "    if not os.path.isdir(to_dir):\n",
    "        os.mkdir(to_dir)\n",
    "    features = gpd.read_file(features_dir).set_index(\"geo_code\")\n",
    "    if local_shape_dir != None:\n",
    "        local_shape = gpd.read_file(local_shape_dir)\n",
    "        local_features = features.loc[local_shape.index, :]\n",
    "        for i in trange(50):\n",
    "            str_i = str(i)\n",
    "            low_pct, high_pct = np.percentile(\n",
    "                local_features[str_i], [low, high], axis=0\n",
    "            )\n",
    "            ax = local_features.plot(\n",
    "                figsize=(40, 40),\n",
    "                alpha=0.55,\n",
    "                vmin=low_pct,\n",
    "                vmax=high_pct,\n",
    "                column=str_i,\n",
    "                cmap=\"bwr\",\n",
    "            )\n",
    "            ax.set_title(f\"Eigenvector {str_i}\")\n",
    "            cx.add_basemap(\n",
    "                ax,\n",
    "                crs=local_features.crs.to_string(),\n",
    "                source=cx.providers.Stamen.TonerLite,\n",
    "            )\n",
    "            plt.savefig(f\"{to_dir}/{str_i}.png\")\n",
    "            plt.cla()\n",
    "    else:  # global case\n",
    "        for i in trange(50):\n",
    "            str_i = str(i)\n",
    "            low_pct, high_pct = np.percentile(\n",
    "                features[str_i], [low, high], axis=0)\n",
    "            ax = features.plot(\n",
    "                figsize=(40, 40),\n",
    "                alpha=0.55,\n",
    "                vmin=low_pct,\n",
    "                vmax=high_pct,\n",
    "                column=str_i,\n",
    "                cmap=\"bwr\",\n",
    "            )\n",
    "            ax.set_title(f\"Eigenvector {str_i}\")\n",
    "            cx.add_basemap(\n",
    "                ax, crs=features.crs.to_string(), source=cx.providers.Stamen.TonerLite\n",
    "            )\n",
    "            plt.savefig(f\"{to_dir}/{str_i}.png\")\n",
    "            plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16523f1d-0ee0-40f3-8390-631b8233e91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
